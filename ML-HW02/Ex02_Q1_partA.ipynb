{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba12121",
   "metadata": {},
   "source": [
    "#### - Sobhan Moradian Daghigh\n",
    "#### - 12/15/2021\n",
    "#### - ML - EX02 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7fc2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f2d7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./HeartDisease/heart.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "505a2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent features: \n",
    "indeps = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4179e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316b8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd7d5df",
   "metadata": {},
   "source": [
    "#### Splite the dataset into 80% of train and 20% of test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b4bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.2)\n",
    "train = pd.DataFrame(x_train)\n",
    "train['target'] = y_train\n",
    "test = pd.DataFrame(x_test)\n",
    "test['target'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5fa750",
   "metadata": {},
   "source": [
    "### Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9f34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_prior_probabilities(dataset):\n",
    "    return np.log(dataset.groupby(by = 'target').apply(lambda x: np.divide(len(x), dataset.shape[0]))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4ed94999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continues with Noraml Distribution\n",
    "def cal_probability_density(mean, cov, x):    \n",
    "    var = multivariate_normal(mean=mean, cov=cov)\n",
    "    prob = var.pdf(x)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "be308637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete\n",
    "def cal_probability(dataset, col, x, class_i):\n",
    "    frequent = dataset.groupby(by='target').apply(lambda a: a.iloc[:, col].value_counts()[x])[class_i]\n",
    "    return frequent / dataset.groupby(by='target').size()[class_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "859ee5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_likelihood_probabilities(df_row, n_unique_labels, dataset, cov, mean_continues):\n",
    "    \n",
    "    df_discrete = df_row[indeps]\n",
    "    df_continues = df_row.drop(indeps)\n",
    "    \n",
    "    likelihood_probabilities = []\n",
    "    for i in range(n_unique_labels):\n",
    "        likelihood = 0\n",
    "    \n",
    "        # For Discretes\n",
    "        for j in range(dataset.shape[1]):\n",
    "            if dataset.columns[j] in indeps:\n",
    "                likelihood += np.log(cal_probability(dataset, j, df_discrete[dataset.columns[j]], i))\n",
    "        \n",
    "        # For Continueses\n",
    "        likelihood += np.log(cal_probability_density(mean_continues[i], cov[i], df_continues))\n",
    "        \n",
    "        likelihood_probabilities.append(likelihood)\n",
    "\n",
    "    return likelihood_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "38d9b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBC_fit(dataset):\n",
    "    \n",
    "    unique_labels = dataset['target'].unique()\n",
    "    n_unique_labels = len(unique_labels)\n",
    "    \n",
    "    dataset_continues = dataset.drop(indeps, axis=1)\n",
    "    dataset_continues['target'] = dataset['target']\n",
    "    dataset_continues0 = dataset_continues[dataset_continues['target'] == 0]\n",
    "    dataset_continues1 = dataset_continues[dataset_continues['target'] == 1]\n",
    "    dataset_continues0 = dataset_continues0.drop('target', axis=1)\n",
    "    dataset_continues1 = dataset_continues1.drop('target', axis=1)\n",
    "        \n",
    "    cov0, mean0 = dataset_continues0.cov(), dataset_continues0.mean()\n",
    "    cov1, mean1 = dataset_continues1.cov(), dataset_continues1.mean()\n",
    "    cov, mean_continues = [cov0, cov1], [mean0, mean1]\n",
    "    \n",
    "    prior_probabilities = cal_prior_probabilities(dataset)\n",
    "\n",
    "    return {\n",
    "      'unique_labels': unique_labels,\n",
    "      'n_unique_labels': n_unique_labels,\n",
    "      'prior_probabilities': prior_probabilities,\n",
    "      'dataset': dataset,\n",
    "      'cov': cov,\n",
    "      'mean_continues': mean_continues\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "617be5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_dataset, nbc):\n",
    "    predictions = []\n",
    "    for i in range(test_dataset.shape[0]):\n",
    "        prior = nbc['prior_probabilities']\n",
    "        likelihood = cal_likelihood_probabilities(test_dataset.iloc[i, :-1], nbc['n_unique_labels'], \n",
    "                                                  nbc['dataset'], nbc['cov'], nbc['mean_continues'])\n",
    "        # log(a*b) = loga + logb\n",
    "        probabilities = prior + likelihood\n",
    "        mx_idx = np.argmax(probabilities)\n",
    "        predictions.append(nbc['unique_labels'][mx_idx])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0f3a37c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "nbc = NBC_fit(train)\n",
    "predictions = predict(test, nbc)\n",
    "accuracy = accuracy_score(test.iloc[:, -1], predictions)\n",
    "print('accuracy: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4209b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
